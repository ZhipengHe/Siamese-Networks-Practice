{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Siamese Neural Network - omniglot dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Import Library"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "import tensorflow as tf\r\n",
    "from tensorflow import keras\r\n",
    "from tensorflow.keras import layers, Input, backend\r\n",
    "import tensorflow_datasets as tfds"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load the Omniglot dataset "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "(ds_train, ds_test), ds_info = tfds.load('omniglot', split=['train','test'], with_info=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "input_shape = ds_info.features['image'].shape\r\n",
    "print(input_shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(105, 105, 3)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "print(list(ds_info.features.keys()))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['image', 'alphabet', 'alphabet_char_id', 'label']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Split the dataset to train and test"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# ds_train = []\r\n",
    "# ds_test = []\r\n",
    "\r\n",
    "# for case in ds[0]:\r\n",
    "#     ds_train.append((case[\"image\"],case[\"alphabet\"]))\r\n",
    "\r\n",
    "# for case in ds[1]:\r\n",
    "#     ds_test.append((case[\"image\"],case[\"alphabet\"]))\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "def normalize_img(case):\r\n",
    "  \"\"\"Normalizes images: `uint8` -> `float32`.\"\"\"\r\n",
    "  return tf.cast(case[\"image\"], tf.float32) / 255., case[\"alphabet\"]\r\n",
    "\r\n",
    "ds_train = ds_train.map(\r\n",
    "  normalize_img, num_parallel_calls=tf.data.experimental.AUTOTUNE)\r\n",
    "ds_train = ds_train.cache()\r\n",
    "ds_train = ds_train.shuffle(ds_info.splits['train'].num_examples)\r\n",
    "ds_train = ds_train.batch(128)\r\n",
    "ds_train = ds_train.prefetch(tf.data.experimental.AUTOTUNE)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "ds_test = ds_test.map(\r\n",
    "    normalize_img, num_parallel_calls=tf.data.experimental.AUTOTUNE)\r\n",
    "ds_test = ds_test.batch(128)\r\n",
    "ds_test = ds_test.cache()\r\n",
    "ds_test = ds_test.prefetch(tf.data.experimental.AUTOTUNE)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "def triplet_loss(y_true, y_pred, margin = 0.4):\r\n",
    "    \"\"\"Implementation of the triplet loss function\r\n",
    "\r\n",
    "    Arguments:\r\n",
    "        y_true : true labels, required when you define a loss in Keras, \r\n",
    "                not applied in this function.\r\n",
    "\r\n",
    "        y_pred (list): python list containing three objects:\r\n",
    "            anchor : the encodings for the anchor data\r\n",
    "            positive : the encodings for the positive data (similar to anchor)\r\n",
    "            negative : the encodings for the negative data (different from anchor)\r\n",
    "        \r\n",
    "        margin (float, optional): m > 0 determines how far the embeddings of \r\n",
    "                    a negative data should be pushed apart. Defaults to 0.4.\r\n",
    "\r\n",
    "    Returns:\r\n",
    "        loss (float): real number, value of the loss\r\n",
    "    \"\"\"\r\n",
    "\r\n",
    "    anchor = y_pred[0]\r\n",
    "    positive = y_pred[1]\r\n",
    "    negative = y_pred[2]\r\n",
    "\r\n",
    "    # squared distance between the anchor and the positive\r\n",
    "    pos_dist = tf.math.reduce_sum(tf.math.square(anchor - positive), axis=1)\r\n",
    "\r\n",
    "    # squared distance between the anchor and the negative\r\n",
    "    neg_dist = tf.math.reduce_sum(tf.math.square(anchor - negative), axis=1)\r\n",
    "\r\n",
    "    # compute loss\r\n",
    "    basic_loss = margin + pos_dist - neg_dist\r\n",
    "    loss = tf.math.maximum(basic_loss,0.0)\r\n",
    "    loss = tf.math.reduce_mean(loss)\r\n",
    "    return loss\r\n",
    "\r\n",
    "\r\n",
    "def contrastive_loss(y_true, y_pred, margin = 0.4):\r\n",
    "    \"\"\"Implementation of the triplet loss function\r\n",
    "\r\n",
    "    Inspired by https://stackoverflow.com/questions/38260113/implementing-contrastive-loss-and-triplet-loss-in-tensorflow\r\n",
    "\r\n",
    "    Args:\r\n",
    "        y_true (int): true label, positive pair (same class) -> 0, \r\n",
    "                    negative pair (different class) -> 1\r\n",
    "        \r\n",
    "        y_pred (list): python list containing two objects in a pair of tensors:\r\n",
    "            left : the encodings for one image data in a pair\r\n",
    "            right : the encodings for the other image data in a pair\r\n",
    "        \r\n",
    "        margin (float, optional): m > 0 determines how far the embeddings of \r\n",
    "                    a negative pair should be pushed apart. Defaults to 0.4.\r\n",
    "\r\n",
    "    Returns:\r\n",
    "        loss (float): real number, value of the loss\r\n",
    "    \"\"\"\r\n",
    "\r\n",
    "    left = y_pred[0]\r\n",
    "    right = y_pred[1]\r\n",
    "\r\n",
    "    # squared distance between the left image and the right image\r\n",
    "    dist = tf.math.reduce_sum(tf.math.square(left - right), axis=1)\r\n",
    "\r\n",
    "    loss_positive = dist\r\n",
    "    loss_negative = tf.math.square(tf.maximum(0., margin - tf.math.sqrt(dist)))\r\n",
    "    \r\n",
    "    loss = y_true * loss_negative + (1 - y_true) * loss_positive\r\n",
    "    loss = 0.5 * tf.math.reduce_mean(loss)\r\n",
    "\r\n",
    "    return loss\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def siamese_networks():\r\n",
    "\r\n",
    "    left_input = Input(shape=input_shape, name=\"left_img\")\r\n",
    "    x = layers.Conv2D(filters=64, kernel_size=(10,10), activation='relu')(left_input)\r\n",
    "    x = layers.MaxPool2D(pool_size=(2,2))(x)\r\n",
    "    x = layers.Conv2D(filters=128, kernel_size=(7,7), activation='relu')(x)\r\n",
    "    x = layers.MaxPool2D(pool_size=(2,2))(x)\r\n",
    "    x = layers.Conv2D(filters=128, kernel_size=(4,4), activation='relu')(x)\r\n",
    "    x = layers.MaxPool2D(pool_size=(2,2))(x)\r\n",
    "    x = layers.Conv2D(filters=256, kernel_size=(4,4), activation='relu')(x)\r\n",
    "    x = layers.Flatten()(x)\r\n",
    "    x = layers.Dense(4096, activation='sigmoid')(x)\r\n",
    "\r\n",
    "    right_input = Input(shape=input_shape, name=\"right_img\")\r\n",
    "    y = layers.Conv2D(filters=64, kernel_size=(10,10), activation='relu')(right_input)\r\n",
    "    y = layers.MaxPool2D(pool_size=(2,2))(y)\r\n",
    "    y = layers.Conv2D(filters=128, kernel_size=(7,7), activation='relu')(y)\r\n",
    "    y = layers.MaxPool2D(pool_size=(2,2))(y)\r\n",
    "    y = layers.Conv2D(filters=128, kernel_size=(4,4), activation='relu')(y)\r\n",
    "    y = layers.MaxPool2D(pool_size=(2,2))(x)\r\n",
    "    y = layers.Conv2D(filters=256, kernel_size=(4,4), activation='relu')(y)\r\n",
    "    y = layers.Flatten()(y)\r\n",
    "    y = layers.Dense(4096, activation='sigmoid')(y)\r\n",
    "\r\n",
    "    L1_layer = layers.Lambda(lambda tensors:backend.abs(tensors[0] - tensors[1]))\r\n",
    "    L1_distance = L1_layer([x, y])\r\n",
    "\r\n",
    "    prediction = layers.Dense(1,activation='sigmoid')(L1_distance)\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "e5fbb69dc477f16c614d0279d3c32a08b8462b181ba1381a242aa9ddc9865207"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}